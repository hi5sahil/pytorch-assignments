{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd15b924",
   "metadata": {},
   "source": [
    "This unmodified version is:\n",
    "\n",
    "* Slower\n",
    "\n",
    "* Finds a suboptimal answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e14c4fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.utils import shuffle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd00e81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-04-09 18:09:44--  http://files.grouplens.org/datasets/movielens/ml-20m.zip\n",
      "Resolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\n",
      "Connecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 198702078 (189M) [application/zip]\n",
      "Saving to: ‘ml-20m.zip’\n",
      "\n",
      "ml-20m.zip          100%[===================>] 189.50M  17.9MB/s    in 11s     \n",
      "\n",
      "2023-04-09 18:09:56 (17.4 MB/s) - ‘ml-20m.zip’ saved [198702078/198702078]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# data is from: https://grouplens.org/datasets/movielens/\n",
    "# in case the link changes in the future\n",
    "\n",
    "!wget -nc http://files.grouplens.org/datasets/movielens/ml-20m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66556cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -n ml-20m.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bf43a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3966c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112486027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1112484580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp\n",
       "0       1        2     3.5  1112486027\n",
       "1       1       29     3.5  1112484676\n",
       "2       1       32     3.5  1112484819\n",
       "3       1       47     3.5  1112484727\n",
       "4       1       50     3.5  1112484580"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('ml-20m/ratings.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80f3c55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can't trust the userId and movieId to be numbered 0...N-1\n",
    "# Let's just set our own ids\n",
    "\n",
    "# current_user_id = 0\n",
    "# custom_user_map = {} # old user id > new user id\n",
    "# def map_user_id(row):\n",
    "#   global current_user_id, custom_user_map\n",
    "#   old_user_id = row['userId']\n",
    "#   if old_user_id not in custom_user_map:\n",
    "#     custom_user_map[old_user_id] = current_user_id\n",
    "#     current_user_id += 1\n",
    "#   return custom_user_map[old_user_id]\n",
    "\n",
    "# df['new_user_id'] = df.apply(map_user_id, axis=1)\n",
    "\n",
    "df.userId = pd.Categorical(df.userId)\n",
    "df['new_user_id'] = df.userId.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80c94304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do the same thing for movie ids\n",
    "# current_movie_id = 0\n",
    "# custom_movie_map = {} # old movie id > new movie id\n",
    "# def map_movie_id(row):\n",
    "#   global current_movie_id, custom_movie_map\n",
    "#   old_movie_id = row['movieId']\n",
    "#   if old_movie_id not in custom_movie_map:\n",
    "#     custom_movie_map[old_movie_id] = current_movie_id\n",
    "#     current_movie_id += 1\n",
    "#   return custom_movie_map[old_movie_id]\n",
    "\n",
    "# df['new_movie_id'] = df.apply(map_movie_id, axis=1)\n",
    "\n",
    "df.movieId = pd.Categorical(df.movieId)\n",
    "df['new_movie_id'] = df.movieId.cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be6d7085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user IDs, movie IDs, and ratings as separate arrays\n",
    "user_ids = df['new_user_id'].values\n",
    "movie_ids = df['new_movie_id'].values\n",
    "ratings = df['rating'].values - 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0e705f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of users and number of movies\n",
    "N = len(set(user_ids))\n",
    "M = len(set(movie_ids))\n",
    "\n",
    "# Set embedding dimension\n",
    "D = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "369ad0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a neural network\n",
    "class Model(nn.Module):\n",
    "  def __init__(self, n_users, n_items, embed_dim, n_hidden=1024):\n",
    "    super(Model, self).__init__()\n",
    "    self.N = n_users\n",
    "    self.M = n_items\n",
    "    self.D = embed_dim\n",
    "\n",
    "    self.u_emb = nn.Embedding(self.N, self.D)\n",
    "    self.m_emb = nn.Embedding(self.M, self.D)\n",
    "    self.fc1 = nn.Linear(2 * self.D, n_hidden)\n",
    "    self.fc2 = nn.Linear(n_hidden, 1)\n",
    "  \n",
    "  def forward(self, u, m):\n",
    "    u = self.u_emb(u) # output is (num_samples, D)\n",
    "    m = self.m_emb(m) # output is (num_samples, D)\n",
    "\n",
    "    # merge\n",
    "    out = torch.cat((u, m), 1) # output is (num_samples, 2D)\n",
    "\n",
    "    # ANN\n",
    "    out = self.fc1(out)\n",
    "    out = F.relu(out)\n",
    "    out = self.fc2(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dda02905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ce5a82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (u_emb): Embedding(138493, 10)\n",
       "  (m_emb): Embedding(26744, 10)\n",
       "  (fc1): Linear(in_features=20, out_features=1024, bias=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model(N, M, D)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7decec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.08, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72c68a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle the data in corresponding order\n",
    "user_ids, movie_ids, ratings = shuffle(user_ids, movie_ids, ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ecb7d6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tensors\n",
    "user_ids_t = torch.from_numpy(user_ids).long()\n",
    "movie_ids_t = torch.from_numpy(movie_ids).long()\n",
    "ratings_t = torch.from_numpy(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "834ddb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make datasets\n",
    "Ntrain = int(0.8 * len(ratings))\n",
    "train_dataset = torch.utils.data.TensorDataset(\n",
    "    user_ids_t[:Ntrain],\n",
    "    movie_ids_t[:Ntrain],\n",
    "    ratings_t[:Ntrain],\n",
    ")\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(\n",
    "    user_ids_t[Ntrain:],\n",
    "    movie_ids_t[Ntrain:],\n",
    "    ratings_t[Ntrain:],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48b82623",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "batch_size = 512\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ba41adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A function to encapsulate the training loop\n",
    "def batch_gd(model, criterion, optimizer, train_iter, test_iter, epochs):\n",
    "  train_losses = np.zeros(epochs)\n",
    "  test_losses = np.zeros(epochs)\n",
    "\n",
    "  for it in range(epochs):\n",
    "    t0 = datetime.now()\n",
    "    train_loss = []\n",
    "    for users, movies, targets in train_loader:\n",
    "      targets = targets.view(-1, 1).float()\n",
    "\n",
    "      # move data to GPU\n",
    "      users, movies, targets = users.to(device), movies.to(device), targets.to(device)\n",
    "\n",
    "      # zero the parameter gradients\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      # Forward pass\n",
    "      outputs = model(users, movies)\n",
    "      loss = criterion(outputs, targets)\n",
    "        \n",
    "      # Backward and optimize\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      train_loss.append(loss.item())\n",
    "\n",
    "    # Get train loss and test loss\n",
    "    train_loss = np.mean(train_loss) # a little misleading\n",
    "    \n",
    "    test_loss = []\n",
    "    for users, movies, targets in test_loader:\n",
    "      users, movies, targets = users.to(device), movies.to(device), targets.to(device)\n",
    "      targets = targets.view(-1, 1).float()\n",
    "      outputs = model(users, movies)\n",
    "      loss = criterion(outputs, targets)\n",
    "      test_loss.append(loss.item())\n",
    "    test_loss = np.mean(test_loss)\n",
    "\n",
    "    # Save losses\n",
    "    train_losses[it] = train_loss\n",
    "    test_losses[it] = test_loss\n",
    "    \n",
    "    dt = datetime.now() - t0\n",
    "    print(f'Epoch {it+1}/{epochs}, Train Loss: {train_loss:.4f}, '\n",
    "          f'Test Loss: {test_loss:.4f}, Duration: {dt}')\n",
    "  \n",
    "  return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3513b92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_losses, test_losses = batch_gd(\n",
    "#     model, criterion, optimizer, train_loader, test_loader, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ad9ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25, Train Loss: 0.8177, Test Loss: 0.7532, Duration: 0:17:40.552894\n",
      "Epoch 2/25, Train Loss: 0.7389, Test Loss: 0.7357, Duration: 0:23:06.453104\n",
      "Epoch 3/25, Train Loss: 0.7216, Test Loss: 0.7203, Duration: 0:23:42.174175\n",
      "Epoch 4/25, Train Loss: 0.7049, Test Loss: 0.7098, Duration: 0:24:05.862396\n",
      "Epoch 5/25, Train Loss: 0.6933, Test Loss: 0.7060, Duration: 0:18:59.608093\n",
      "Epoch 6/25, Train Loss: 0.6857, Test Loss: 0.6991, Duration: 0:16:51.731074\n",
      "Epoch 7/25, Train Loss: 0.6804, Test Loss: 0.6969, Duration: 0:11:26.841609\n",
      "Epoch 8/25, Train Loss: 0.6763, Test Loss: 0.6945, Duration: 0:11:49.029118\n",
      "Epoch 9/25, Train Loss: 0.6731, Test Loss: 0.6929, Duration: 0:12:31.222600\n",
      "Epoch 10/25, Train Loss: 0.6704, Test Loss: 0.6923, Duration: 0:13:12.614447\n",
      "Epoch 11/25, Train Loss: 0.6680, Test Loss: 0.6907, Duration: 0:11:54.666144\n",
      "Epoch 12/25, Train Loss: 0.6658, Test Loss: 0.6924, Duration: 0:15:36.068277\n"
     ]
    }
   ],
   "source": [
    "# profile this using\n",
    "# %prun - magic command for profiler\n",
    "%prun train_losses, test_losses = batch_gd( \\\n",
    "    model, criterion, optimizer, train_loader, test_loader, 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e59cb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the train loss and test loss per iteration\n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(test_losses, label='test loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9439bce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
